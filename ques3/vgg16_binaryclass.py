# -*- coding: utf-8 -*-
"""vgg16_binaryClass.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1d_yxPu7EXBZBXPb0AwbnRp1_xfOEQm3T
"""

import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow as tf
import keras
from keras.models import Sequential
from keras.layers import Dense, Conv2D, MaxPool2D , Flatten
from keras.preprocessing.image import ImageDataGenerator

from keras.applications.vgg16 import VGG16
from keras.models import Model
from keras.optimizers import Adam
from keras.callbacks import ModelCheckpoint, EarlyStopping
from PIL import Image
import matplotlib.pyplot as plt

from google.colab import drive
drive.mount('/content/drive')

trdata = ImageDataGenerator()
traindata = trdata.flow_from_directory(directory=r"/content/drive/MyDrive/dataset/train",target_size=(224,224))
tsdata = ImageDataGenerator()
testdata = tsdata.flow_from_directory(directory=r"/content/drive/MyDrive/dataset/test", target_size=(224,224))


tf.keras.applications.vgg16.VGG16(
    include_top=False,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling='avg',
    classes=2,
    classifier_activation='softmax'
)


model = Sequential()
model.add(tf.keras.applications.vgg16.VGG16(
    include_top=False,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling='avg',
    classes=2,
    classifier_activation='softmax'
))
model.add(Flatten())
model.add(Dense(units=4096,activation="relu"))
model.add(Dense(units=4096,activation="relu"))
model.add(Dense(units=2, activation="softmax"))



opt = Adam(lr=0.0001)
model.compile(optimizer=opt, loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])

for layer in model.layers[0].layers:
    layer.trainable = False
    
model.summary()

import cv2
from google.colab.patches import cv2_imshow

file_name = '/content/drive/MyDrive/dataset/train/African/af_tr248.jpg'

image = cv2.imread(file_name)
cv2_imshow(image)

hist = model.fit(traindata, validation_data = testdata, epochs = 30,  batch_size=30)

plt.plot(hist.history["accuracy"])
plt.plot(hist.history['val_accuracy'])
plt.plot(hist.history['loss'])       
plt.plot(hist.history['val_loss'])
plt.title("model accuracy")
plt.ylabel("Accuracy")
plt.xlabel("Epoch")
plt.legend(["Accuracy","Validation Accuracy","loss","Validation Loss"])
plt.show()

model.save('/content/drive/MyDrive/model/elephant_model.h5')

model.save_weights('/content/drive/MyDrive/model/elephant_weights.h5')

width, height = 224, 224
model_p = '/content/drive/MyDrive/model/elephant_model.h5'
weight_p = '/content/drive/MyDrive/model/elephant_weights.h5'

model = tf.keras.models.load_model(model_p)
model.load_weights(weight_p)

def fpredict(file):
    if not os.path.isfile(file):
        return "Error: file does not exist."
    try:
        test_image = tf.keras.utils.load_img(file, target_size=(width,height))
        test_image = tf.keras.utils.img_to_array(test_image)
        test_image = np.expand_dims(test_image, axis=0)
    except Exception as e:
        return f"Error: {e}"
    if not 'model' in globals():
        return "Error: model is not defined."
    try:
        array = model.predict(test_image)
        result = array[0]
    except Exception as e:
        return f"Error: {e}"
    if result[0] >= 0.5 :
        an = 'African Elephant'
    elif result[1]>= 0.5:
        an = 'Asian Elephant'
    else:
        an = "Not sure"
    return an

fpredict('/content/drive/MyDrive/elephsnt.jpg')

